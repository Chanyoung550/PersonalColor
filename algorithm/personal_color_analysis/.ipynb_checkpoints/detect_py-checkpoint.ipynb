{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7e5bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "import dlib\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class DetectFace:\n",
    "    def __init__(self, image):\n",
    "        # initialize dlib's face detector (HOG-based)\n",
    "        # and then create the facial landmark predictor\n",
    "        self.detector = dlib.get_frontal_face_detector()\n",
    "        self.predictor = dlib.shape_predictor('../res/shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "        #face detection part\n",
    "        self.img = cv2.imread(image)\n",
    "        #if self.img.shape[0]>500:\n",
    "        #    self.img = cv2.resize(self.img, dsize=(0,0), fx=0.8, fy=0.8)\n",
    "\n",
    "        # init face parts\n",
    "        self.right_eyebrow = []\n",
    "        self.left_eyebrow = []\n",
    "        self.right_eye = []\n",
    "        self.left_eye = []\n",
    "        self.left_cheek = []\n",
    "        self.right_cheek = []\n",
    "\n",
    "        # detect the face parts and set the variables\n",
    "        self.detect_face_part()\n",
    "\n",
    "\n",
    "    # return type : np.array\n",
    "    def detect_face_part(self):\n",
    "        face_parts = [[],[],[],[],[],[],[]]\n",
    "        # detect faces in the grayscale image\n",
    "        rect = self.detector(cv2.cvtColor(self.img, cv2.COLOR_BGR2GRAY), 1)[0]\n",
    "\n",
    "        # determine the facial landmarks for the face region, then\n",
    "        # convert the landmark (x, y)-coordinates to a NumPy array\n",
    "        shape = self.predictor(cv2.cvtColor(self.img, cv2.COLOR_BGR2GRAY), rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "        idx = 0\n",
    "        # loop over the face parts individually\n",
    "        for (name, (i, j)) in face_utils.FACIAL_LANDMARKS_IDXS.items():\n",
    "            face_parts[idx] = shape[i:j]\n",
    "            idx += 1\n",
    "        face_parts = face_parts[1:5]\n",
    "        # set the variables\n",
    "        # Caution: this coordinates fits on the RESIZED image.\n",
    "        self.right_eyebrow = self.extract_face_part(face_parts[0])\n",
    "        #cv2.imshow(\"right_eyebrow\", self.right_eyebrow)\n",
    "        #cv2.waitKey(0)\n",
    "        self.left_eyebrow = self.extract_face_part(face_parts[1])\n",
    "        self.right_eye = self.extract_face_part(face_parts[2])\n",
    "        self.left_eye = self.extract_face_part(face_parts[3])\n",
    "        # Cheeks are detected by relative position to the face landmarks\n",
    "        self.left_cheek = self.img[shape[29][1]:shape[33][1], shape[4][0]:shape[48][0]]\n",
    "        self.right_cheek = self.img[shape[29][1]:shape[33][1], shape[54][0]:shape[12][0]]\n",
    "\n",
    "    # parameter example : self.right_eye\n",
    "    # return type : image\n",
    "    def extract_face_part(self, face_part_points):\n",
    "        (x, y, w, h) = cv2.boundingRect(face_part_points)\n",
    "        crop = self.img[y:y+h, x:x+w]\n",
    "        adj_points = np.array([np.array([p[0]-x, p[1]-y]) for p in face_part_points])\n",
    "\n",
    "        # Create an mask\n",
    "        mask = np.zeros((crop.shape[0], crop.shape[1]))\n",
    "        cv2.fillConvexPoly(mask, adj_points, 1)\n",
    "        mask = mask.astype(np.bool)\n",
    "        crop[np.logical_not(mask)] = [255, 0, 0]\n",
    "\n",
    "        return crop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
